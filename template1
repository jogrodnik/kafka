#!/bin/bash
set -euf -o pipefail

cd "$(dirname "$0")/../secrets/" || exit

echo "ðŸ”–  Generating some fake certificates and other secrets."
echo "âš ï¸  Remember to type in \"yes\" for all prompts."
sleep 2

TLD="local"
PASSWORD="awesomekafka"

# Generate CA key
openssl req -new -x509 -keyout fake-ca-1.key \
	-out fake-ca-1.crt -days 9999 \
	-subj "/CN=ca1.${TLD}/OU=CIA/O=REA/L=Melbourne/S=VIC/C=AU" \
	-passin pass:$PASSWORD -passout pass:$PASSWORD

for i in broker control-center metrics schema-registry kafka-tools rest-proxy; do
	echo ${i}
	# Create keystores
	keytool -genkey -noprompt \
		-alias ${i} \
		-dname "CN=${i}.${TLD}, OU=CIA, O=REA, L=Melbourne, S=VIC, C=AU" \
		-keystore kafka.${i}.keystore.jks \
		-keyalg RSA \
		-storepass $PASSWORD \
		-keypass $PASSWORD

	# Create CSR, sign the key and import back into keystore
	keytool -keystore kafka.$i.keystore.jks -alias $i -certreq -file $i.csr -storepass $PASSWORD -keypass $PASSWORD

	openssl x509 -req -CA fake-ca-1.crt -CAkey fake-ca-1.key -in $i.csr -out $i-ca1-signed.crt -days 9999 -CAcreateserial -passin pass:$PASSWORD

	keytool -keystore kafka.$i.keystore.jks -alias CARoot -import -file fake-ca-1.crt -storepass $PASSWORD -keypass $PASSWORD

	keytool -keystore kafka.$i.keystore.jks -alias $i -import -file $i-ca1-signed.crt -storepass $PASSWORD -keypass $PASSWORD

	# Create truststore and import the CA cert.
	keytool -keystore kafka.$i.truststore.jks -alias CARoot -import -file fake-ca-1.crt -storepass $PASSWORD -keypass $PASSWORD

	echo $PASSWORD >${i}_sslkey_creds
	echo $PASSWORD >${i}_keystore_creds
	echo $PASSWORD >${i}_truststore_creds
done


The Unity 2.0 system uses  Kafka Confluent topics in the process of asynchronous message processing. The cluster of brokers providing these topics is installed in an on-prem environment.

The diagram below ( read lines ) shows the internal current flow of information in the Unity 2.0 pipeline.

The current architecture significantly impacts the load of the Kafka topics on-prem and network traffic between on-prem and GCP GKE during the processing of the pipeline messages.
 
To eliminate these inefficiencies of the Unity 2 Pipelines, we want to implement a dedicated Kafka on-prem on the GKE cluster for each project (Kubernetes namespace) so the traffic is consistent with the diagram ( green line )

Consequently, all internal traffic will be based on the Kafka cluster topic dedicated to each project.

At the moment, we have a Kafka cluster installed on GKE.
The goal of this epic is to do all tasks necessary to run a full production deployment of Kafka on GKE in accordance with the requirements of the HSBC procedure 

echo "âœ…  All done."
